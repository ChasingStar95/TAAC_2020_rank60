2020腾讯广告大赛复赛60名方案--基于图神经网络
---

上半年系统的学习了新兴的图神经网络，并且参加了今年的腾讯广告大赛对学到的算法进行验证。

今年的赛题是通过 用户点击广告 的记录，来预测用户的年龄组和性别两个属性。其中点击的广告给出了多个分类属性，用户则没有任何可用做特征的属性。

训练集和测试集的划分是完全按照用户id来的，这样用户id在训练集和测试集中就完全没有重合，可用的特征就只有广告信息了。

目前看来大部分参赛队伍的解决方案都是将点击记录按用户分组，将每个用户点击的广告序列套在transformer、bilstm等文本分类的模型上。模型的效果比较依赖与word2vec、prone等预训练的embedding特征，其次是参赛队伍的调参能力和多模型的融合。

理论上说，序列分类模型只能拿到用户的一阶邻居，也就是点击广告的特征，而图神经网络可以看到点击相同广告的用户信息，应该是有优势的。

我参加比赛的初衷是为了在这个二部图数据上验证图神经网络的各种算法，也没有其他队员可以一起调参，比赛过程中进度非常慢，以至于最后一周才开始尝试序列模型及多模型融合的策略。

一方面在模型没有经过充分调参的情况下可以做到60名，起码说明图神经网络的work的。

另一方面图神经网络对比传统序列分类模型没有显示出明显优势，其中实验过程中尝试了cluster-gcn、graphsaint等图采样算法，以及DGI、GMI、InfoGraph等预训练策略，均没有任何提升。

最终采用的graphsage难以达到传统模型的效果，经过分析可能是卷积核过于简单，因此改造了卷积核增大其表达能力。

最后阶段把图神经网络得到的节点表示作为特征，使用bilstm和transformer融合。这两个模型没有得到充分的调参，应该还有提升空间。此外复赛的其他选手很多都采用了十折二十折，以及更多模型的融合。这里由于时间关系只使用了五折。

比赛过程中本来打算实现滴滴的Gemini模型，直接建模点击相同广告的用户网络，以及被同一用户点击的广告网络，这样可以比graphsage建立更深的网络关系。但是在用pandas进行二阶关系处理的时候，内存不够。

# 0、建立字典文件，并进行id映射

由于数据中ID是不连续的，第一个脚本先将原始id映射到了连续空间。

此外还做了数据集的合并等预处理工作。

# 1、创建图特征

预处理得到 用户-广告 二分图的边、用户和广告节点的属性、以及用于5折交叉验证的标记。

# 2、训练prone算法的128维embedding

这里将用户和点击的广告建图，并且将广告的特征作为新的节点与广告id相连，这样可以得到所有特征的embedding表示。

此外预训练了一个16维的embedding，用于微调。128维的向量是固定的。

这里没有对比建图的方式等起到的作用是否是正向的。

# 3、训练128维word2vec向量

简单的将同一用户点击的广告多个特征作为序列，训练word2vec向量，这个是初赛阶段很多人分享的trick。

# 4、训练graphsage模型

使用的是有监督的GraphSage模型。

卷积核做了修改，将邻居的聚合过程用max和mean的结果进行了拼接，对聚合过程增加了没有softmax的注意力机制，对卷积的结果增加了一层全连接增加模型复杂度。

采样过程使用了无放回采样。另外这里用的是DGL框架，采样后的节点构成新的子图，比原论文算法会节省很多空间。

由于二部图是异构图，不能直接使用同构图的卷积层。解决的办法是使用DGL提供的HeteroGraphConv，对点击和被点击两个关系使用两个不同的卷积核，将卷积结果进行简单的相加。

预测的时候将10个年龄组和2个性别分类合在一起组成二十分类问题，并且使用了labelsmooth策略。

优化器使用的是Adam，学习率衰减策略是OneCycle策略。即学习率从小增长到最大，再慢慢降下来，是一种退火策略。

# 5、创建序列分类模型使用的数据集

就是提前按用户分组，生成用户对应的广告序列。

# 6、训练bilstm模型

简单的将图模型的节点embedding作为输入，使用了一层Bilstn，用max、mean、attention、capsule进行池化，将多种池化结果拼接，用MLP分类。其他的基本类似图模型。

# 7、训练transformer模型

将bilstm层换成transformer，这里没有bilstm表现好，可能是参数没有调好。

# 8、融合

融合过程这里没有给出，需要手动跑出前两个模型五折的结果，然后将bilstm模型得到的20分类概率*0.7，transformer的结果*0.3，相加再进行argmax。

# 数据

初赛数据我看到有人发在了百度aistudio上，可以在这里找到：https://aistudio.baidu.com/aistudio/datasetdetail/33655

GraphSage模型这里用的是256维，如果使用500维的话效果更好，由于时间关系比赛中没有提交。

embedding也可以更大，似乎有提升，由于时间有限没有尝试。

可能需要V100以及100G内存才能跑起来。

# 结果

graphsage线下1.4638，线上1.467052

transformer线下1.463907，线上1.470614

bilstm线下1.464788，线上1.470816

transformer和bilstm融合线下1.465179，线上1.471016